{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a21845-5edc-410a-ab41-5196319ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3786fdb-7af6-4ce2-b730-90c60a5d896f",
   "metadata": {},
   "source": [
    "# Regression Models Lab\n",
    "## Linear and logistic regression: theory and practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6ff4b-e18a-4580-8c7c-54f4c7ef2dc9",
   "metadata": {},
   "source": [
    "In this lab you'll revisit and expand on your knowledge of modelling in general, as well as the fundamentals of linear and logistic regression. As a reminder, _linear regression_ is a regression model (regressor), and _logistic regression_ is a classification model (classifier).\n",
    "\n",
    "This time, you'll use generated data, in order to separate some of the complexity of handling various datasets from inspecting and evaluating models.\n",
    "\n",
    "**Use vectorization as much as possible!** You should be able to complete the lab using for-loops only to track the training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a9603-c803-4728-a69d-b6acfe2bad8a",
   "metadata": {},
   "source": [
    "### Problem 1. Generate some data for multiple linear regression (1 point)\n",
    "As an expansion to the lecture, you'll create a dataset and a model.\n",
    "\n",
    "Create a dataset of some (e.g., 50-500) observations of several (e.g., 5-20) independent features. You can use random generators for them; think about what distributions you'd like to use. Let's call them $x_1, x_2, ..., x_m$. The data matrix $X$ you should get should be of size $n \\times m$. It's best if all features have different ranges.\n",
    "\n",
    "Create the dependent variable by assigning coefficients $\\bar{a_1}, \\bar{a_2}, ..., \\bar{a_m}, \\bar{b}$ and calculating $y$ as a linear combination of the input features. Add some random noise to the functional values. I've used bars over coefficients to avoid confusion with the model parameters later.\n",
    "\n",
    "Save the dataset ($X$ and $y$), and \"forget\" that the coefficients have ever existed. \"All\" you have is the file and the implicit assumption that there is a linear relationship between $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6879424-5cd5-4c0f-b81d-3ecdfb9c2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.323286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.983968</td>\n",
       "      <td>-3.508710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.967936</td>\n",
       "      <td>-2.092301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.951904</td>\n",
       "      <td>-2.462988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.935872</td>\n",
       "      <td>-2.875730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4.935872</td>\n",
       "      <td>13.084472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4.951904</td>\n",
       "      <td>12.420320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.967936</td>\n",
       "      <td>12.912016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4.983968</td>\n",
       "      <td>12.966135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.420818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x          y\n",
       "0   -3.000000  -3.323286\n",
       "1   -2.983968  -3.508710\n",
       "2   -2.967936  -2.092301\n",
       "3   -2.951904  -2.462988\n",
       "4   -2.935872  -2.875730\n",
       "..        ...        ...\n",
       "495  4.935872  13.084472\n",
       "496  4.951904  12.420320\n",
       "497  4.967936  12.912016\n",
       "498  4.983968  12.966135\n",
       "499  5.000000  12.420818\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate x values using linspace\n",
    "x = np.linspace(-3, 5, 500)\n",
    "\n",
    "# Generate y values based on the equation y = 2x + 3 with added noise\n",
    "noise = np.random.normal(0, 0.5, x.shape)  # Add some Gaussian noise\n",
    "y = 2 * x + 3 + noise\n",
    "\n",
    "# Convert x and y into a DataFrame\n",
    "dataset = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc03ce0-9ce6-458d-bb33-c08b7961a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>9.507143</td>\n",
       "      <td>73.199394</td>\n",
       "      <td>598.658484</td>\n",
       "      <td>1560.186404</td>\n",
       "      <td>187.147961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.580836</td>\n",
       "      <td>86.617615</td>\n",
       "      <td>601.115012</td>\n",
       "      <td>7080.725778</td>\n",
       "      <td>3045.800826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>9.699099</td>\n",
       "      <td>83.244264</td>\n",
       "      <td>212.339111</td>\n",
       "      <td>1818.249672</td>\n",
       "      <td>945.663470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>3.042422</td>\n",
       "      <td>52.475643</td>\n",
       "      <td>431.945019</td>\n",
       "      <td>2912.291402</td>\n",
       "      <td>1029.839072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.394939</td>\n",
       "      <td>29.214465</td>\n",
       "      <td>366.361843</td>\n",
       "      <td>4560.699842</td>\n",
       "      <td>1850.326991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.737966</td>\n",
       "      <td>55.385428</td>\n",
       "      <td>969.302536</td>\n",
       "      <td>5230.978442</td>\n",
       "      <td>1400.986474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.629399</td>\n",
       "      <td>6.957487</td>\n",
       "      <td>45.454106</td>\n",
       "      <td>627.558080</td>\n",
       "      <td>5843.143119</td>\n",
       "      <td>2149.099792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.901158</td>\n",
       "      <td>0.454464</td>\n",
       "      <td>28.096319</td>\n",
       "      <td>950.411484</td>\n",
       "      <td>8902.637839</td>\n",
       "      <td>3154.608690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.455657</td>\n",
       "      <td>6.201326</td>\n",
       "      <td>27.738118</td>\n",
       "      <td>188.121160</td>\n",
       "      <td>4636.984049</td>\n",
       "      <td>2135.875646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.353352</td>\n",
       "      <td>5.836561</td>\n",
       "      <td>7.773464</td>\n",
       "      <td>974.394808</td>\n",
       "      <td>9862.107445</td>\n",
       "      <td>3473.416582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_1  Feature_2  Feature_3   Feature_4    Feature_5       Target\n",
       "0    0.374540   9.507143  73.199394  598.658484  1560.186404   187.147961\n",
       "1    0.155995   0.580836  86.617615  601.115012  7080.725778  3045.800826\n",
       "2    0.020584   9.699099  83.244264  212.339111  1818.249672   945.663470\n",
       "3    0.183405   3.042422  52.475643  431.945019  2912.291402  1029.839072\n",
       "4    0.611853   1.394939  29.214465  366.361843  4560.699842  1850.326991\n",
       "..        ...        ...        ...         ...          ...          ...\n",
       "95   0.992965   0.737966  55.385428  969.302536  5230.978442  1400.986474\n",
       "96   0.629399   6.957487  45.454106  627.558080  5843.143119  2149.099792\n",
       "97   0.901158   0.454464  28.096319  950.411484  8902.637839  3154.608690\n",
       "98   0.455657   6.201326  27.738118  188.121160  4636.984049  2135.875646\n",
       "99   0.353352   5.836561   7.773464  974.394808  9862.107445  3473.416582\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_observations = 100\n",
    "n_features = 5\n",
    "\n",
    "# Generate random features with different ranges using vectorized operations\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = np.random.rand(n_observations, n_features) * np.array([1, 10, 100, 1000, 10000])\n",
    "\n",
    "# Assign arbitrary coefficients for the linear combination\n",
    "true_coefficients = np.array([2, -3, 4.5, -1.5, 0.5])\n",
    "\n",
    "# Calculate the dependent variable using vectorized operations and add noise\n",
    "noise = np.random.normal(0, 10, n_observations)  # Gaussian noise\n",
    "y = X @ true_coefficients + noise  # Matrix multiplication using @ operator\n",
    "\n",
    "# Convert to a DataFrame for easier handling\n",
    "data = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(n_features)])\n",
    "data['Target'] = y\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7935ded0-6873-48bf-86bd-34c98deef96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>9.507143</td>\n",
       "      <td>73.199394</td>\n",
       "      <td>598.658484</td>\n",
       "      <td>1560.186404</td>\n",
       "      <td>187.147961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.580836</td>\n",
       "      <td>86.617615</td>\n",
       "      <td>601.115012</td>\n",
       "      <td>7080.725778</td>\n",
       "      <td>3045.800826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>9.699099</td>\n",
       "      <td>83.244264</td>\n",
       "      <td>212.339111</td>\n",
       "      <td>1818.249672</td>\n",
       "      <td>945.663470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>3.042422</td>\n",
       "      <td>52.475643</td>\n",
       "      <td>431.945019</td>\n",
       "      <td>2912.291402</td>\n",
       "      <td>1029.839072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.394939</td>\n",
       "      <td>29.214465</td>\n",
       "      <td>366.361843</td>\n",
       "      <td>4560.699842</td>\n",
       "      <td>1850.326991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3   Feature_4    Feature_5       Target\n",
       "0   0.374540   9.507143  73.199394  598.658484  1560.186404   187.147961\n",
       "1   0.155995   0.580836  86.617615  601.115012  7080.725778  3045.800826\n",
       "2   0.020584   9.699099  83.244264  212.339111  1818.249672   945.663470\n",
       "3   0.183405   3.042422  52.475643  431.945019  2912.291402  1029.839072\n",
       "4   0.611853   1.394939  29.214465  366.361843  4560.699842  1850.326991"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv('multiple_linear_regression_dataset.csv', index=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb4164-eaa3-4b76-ae3f-36da95416b7b",
   "metadata": {},
   "source": [
    "### Problem 2. Check your assumption (1 point)\n",
    "Read the dataset you just saved (this is just to simulate starting a new project). It's a good idea to test and verify our assumptions. Find a way to check whether there really is a linear relationship between the features and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c8452-5eb1-4719-88da-372331cfce82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5f9a49-cee6-4537-b82f-d8148a45c0c2",
   "metadata": {},
   "source": [
    "### Problem 3. Figure out the modelling function (1 point)\n",
    "The modelling function for linear regression is of the form\n",
    "$$ \\tilde{y} = \\sum_{i=1}^{m}a_i x_i + b $$\n",
    "\n",
    "If you want to be clever, you can find a way to represent $b$ in the same way as the other coefficients.\n",
    "\n",
    "Write a Python function which accepts coefficients and data, and ensure (test) it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800a26d-3204-49ad-8a83-37edf0f4128f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea9d650-0994-4ae8-bba9-3b8fdecbdd3e",
   "metadata": {},
   "source": [
    "### Problem 4. Write the cost function and compute its gradients (1 point)\n",
    "Use MSE as the cost function $J$. Find a way to compute, calculate, or derive its gradients w.r.t. the model parameters $a_1, ..., a_m, b$\n",
    "\n",
    "Note that computing the cost function value and its gradients are two separate operations. Quick reminder: use vectorization to compute all gradients (maybe with the exception of $\\frac{\\partial J}{\\partial b}$) at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99388ae1-1b23-4233-acf9-daf589bba07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bad786e-4299-4900-ae86-16cbd2235a6e",
   "metadata": {},
   "source": [
    "### Problem 5. Perform gradient descent (1 point)\n",
    "Perform weight updates iteratively. Find a useful criterion for stopping. For most cases, just using a fixed (large) number of steps is enough.\n",
    "\n",
    "You'll need to set a starting point (think about which one should be good, and how it matters); and a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4bc3bd-6b2c-4f40-9e94-40557a2325d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d18a168f-de4c-4035-88db-7350c2b91745",
   "metadata": {},
   "source": [
    "### Problem 6. Do other cost functions work? (2 points)\n",
    "Repeat the process in problems 4 and 5 with MAE, and then again - with the [Huber loss](https://en.wikipedia.org/wiki/Huber_loss). Both of them are less sensitive to outliers / anomalies than MSE); with the Huber loss function being specifically made for datasets with outliers.\n",
    "\n",
    "Explain your findings. Is there a cost function that works much better? How about speed of training (measured in wall time)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0eb74-7b3d-4aa8-9749-dcb55e918a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d4176d1-6cad-4830-824c-1d27e50efe89",
   "metadata": {},
   "source": [
    "### Problem 7. Experiment with the learning rate (1 point)\n",
    "Use your favorite cost function. Run several \"experiments\" with different learning rates. Try really small, and really large values. Observe and document your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f04525-95f3-427d-8763-27af6839cb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91385302-2fc1-48a4-a453-cce7f038e9c2",
   "metadata": {},
   "source": [
    "### Problem 8. Generate some data for classification (1 point)\n",
    "You'll need to create two clusters of points (one cluster for each class). I recomment using `scikit-learn`'s `make_blobs()` ([info](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)). Use as many features as you used in problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948009d-6af6-468c-ac6e-bacd4f75498c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6246890-0808-40e1-b892-fa1d11fd088c",
   "metadata": {},
   "source": [
    "### Problem 9. Perform logistic regression (1 point)\n",
    "Reuse the code you wrote in problems 3-7 as much as possible. If you wrote vectorized functions with variable parameters - you should find this easy. If not - it's not too late to go back and refactor your code.\n",
    "\n",
    "The modelling function for logistic regression is\n",
    "$$ \\tilde{y} = \\frac{1}{1+\\exp{(-\\sum_{i=1}^{m}a_i x_i + b)}}$$. Find a way to represent it using as much of your previous code as you can.\n",
    "\n",
    "The most commonly used loss function is the [cross-entropy](https://en.wikipedia.org/wiki/Cross-entropy).\n",
    "\n",
    "Experiment with different learning rates, basically repeating what you did in problem 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e100b-1627-4300-8d2e-98e8b438e046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "411df95f-5f16-4c37-8649-2c495eb96974",
   "metadata": {},
   "source": [
    "### * Problem 10. Continue experimenting and delving deep into ML\n",
    "You just saw how modelling works and how to implement some code. Some of the things you can think about (and I recommend you pause and ponder on some of them are):\n",
    "* Code: OOP can be your friend sometimes. `scikit-learn`'s models have `fit()`, `predict()` and `score()` methods.\n",
    "* Data: What approaches work on non-generated data?\n",
    "* Evaluation: How well do different models (and their \"settings\" - hyperparameters) actually work in practice? How do we evaluate a model in a meaningful way?\n",
    "* Optimization - maths: Look at what `optimizers` (or solvers) are used in `scikit-learn` and why. Many \"tricks\" revolve around making the algorithm converge (finish) in fewer iterations, or making it more numerically stable.\n",
    "* Optimization - code: Are there ways to make the code run fastr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08101fb6-d53f-4dc9-8f37-d07478c9e220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
